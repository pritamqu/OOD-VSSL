num_workers: 64 # this will be divided by number of gpus in each node
num_node: 2 # num_node multiplies batch size # ignored
apex: true # actually using pytorch amp
apex_opt_level: "O1" # "O0 for FP32 training, O1 for mixed precision training.
sync_bn: true

progress:
    print_freq: 10
    log2tb: false
    wandb: false
    wandb_all: false

dataset:
    name: "kinetics400"
    fold: 1
    batch_size: 384 # effective batch size = cfg['num_node'] * cfg['batch_size']
    clip_duration: 2.0
    video_fps: 8.
    crop_size: 112
    return_video: true
    return_audio: false
    vid_transform: "strong"
    train:
        split: "train"
        mode: "clip2"
        clips_per_video: 1
        aug_mode: 'train'
        use_shuffle: true
        drop_last: true
        vid_aug_kwargs:
            color: [0.6, 0.6, 0.6, 0.15] # [0.4, 0.4, 0.4, 0.2]
            crop_scale: [0.2, 0.766] #
            p_flip: 0.5               # change it to 0 to turn off
            p_gray: 0.2  #            # change it to 0 to turn off
            p_blur: 0.5  #            # change it to 0 to turn off
            pad_missing: true
            normalize: true
            totensor: true

hyperparams:
    num_epochs: 800 # full training
    stop_epoch: 800 # stop before the scheduled train during ablation
    optimizer:
        name: "adamw"
        betas: [0.9, 0.95] # [0.9, 0.999]
    lr:
        name: "cosine"
        warmup_epochs: 30
        warmup_lr: 0
        base_lr: 0.0003 # for effective batch size 
        final_lr: 0
        predictor_lr: 'relative' # either 10xbase_lr or pass value
    weight_decay:
        name: "cosine"
        warmup_epochs: 0
        warmup: 0
        base: 0.05 
        final: 0.05
        predictor_wd: 0.
    ema:
        name: "cosine"
        warmup_epochs: 0
        warmup: 0
        base: 0.997
        final: 1
    temp_kwargs:
        warmup_teacher_temp: 0.04
        warmup_teacher_temp_epochs: 30
        teacher_temp: 0.07
        student_temp: 0.1
model:
    name: "VideoDINO"
    type: 'dino'
    kwargs: # confirm these with the setup mentioned above
        frame_size: [3, 112, 112]
        num_frames: 16
        vid_patch_spatial: [16, 16]
        vid_patch_temporal: 4
        apply_cls_token: true 
        encoder_cfg: 'base_encoder'
        projector_cfg: '2048-gelu-3-256-8192' # '2048-3-2048'
        center_momentum: 0.9
    fwd_kwargs:
        mask_ratio: 0.0
        clip_grad: 0.0 # Maximal parameter gradient norm if using gradient clipping. Clipping with norm .3 ~ 1.0 can help optimization for larger ViT architectures. 0 for disabling.
        freeze_last_layer: 0 # Number of epochs during which we keep the output layer fixed. Typically doing so during the first epoch helps training. Try increasing this value if the loss does not decrease.
